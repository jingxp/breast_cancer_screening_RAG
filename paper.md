# Using deep learning model to safely exclude lesions with only ultrafast breast MRI: a feasibility study

**Introduction**

Dynamic contrast-enhanced MRI (DCE-MRI) of the breast has been widely used as a supplementary screening tool for breast cancer screening. Breast MRI could not only detect more breast cancers than mammography, but also detect cancers at an earlier stage \[1\]. Especially for women with extremely dense breast, supplemental MRI has the potential to reduce interval cancers\[2\]. These advantages have led to a renewed interest of providing breast MRI to a larger population for screening \[3\]. However, cost-effectiveness is still the biggest obstacle for a wider application of this sensitive modality\[4\].

The most promising approaches to reduce the cost of breast MRI is to improve the throughput of the MRI scanner by shortening the acquisition time \[5–8\] and reduce radiologists’ work load to shorten the interpretation time \[9\]. Current diagnostic breast MRI protocols take up to 20 minutes. Several abbreviated protocols have been proposed to replace the standard protocol for screening \[10, 11\]. A recent multi-center multi-reader study \[12\] found that time-resolved angiography with stochastic trajectories (TWIST)\[13\] alone can achieve a comparable sensitivity (84% vs 86%) and higher specificity (82% vs 76%) compared to the full diagnostic protocol, when interpreted by radiologists. This TWIST alone protocol, requiring less than 2 minutes of magnet-time, can thus accelerate the scanning process.

Image interpretation is another bottleneck in breast cancer screening with MRI. The average interpretation time in different studies varied from 25s to 178s \[11\]. It is worth noting that the cancer rate in a screening study may be only 15.5 per 1000 \[14\], which implies that radiologists spent most of their time on reading normal scans without suspicious lesions. On the other hand, the reading quality is also relate to the total number of examinations and the position of a certain examination in the queue\[15\]. Short reading batch and risk-based reading queue may help further improve radiologists’ performance.

The combination of artificial intelligence (AI) and ultrafast MRI could help to improve the efficiency of breast MRI screening by automatically exclude scans without lesion. On the one hand, by pinpointing suspicious lesions from numerous screening scans and prioritizing them according to risk could help reduce the workload and improve efficiency. On the other hand, an early stop strategy could also apply to patients without suspicious lesions enhanced in ultrafast MRI. Since malignant lesions are more likely to enhance rapidly at the early stage of DCE-MRI\[16, 17\], cancellation or adjustment of further sequences based on the output of ultrafast MRI could help reduce scanning time and thus improve the throughput. Meanwhile, based on the real time analysis of the ultrafast sequences, additional scanning (e.g., T2, DWI) or even a full diagnostic protocol could still be performed if any abnormalities are detected.

We hypothesized that a deep learning model, with only TWIST sequences as input, might be able to pinpoint normal MRI exams without human intervention. Integrating this deep learning system in the screening workflow could improve the throughput and reduce the radiologist’s workload. Therefore, the aim of this study is to develop and evaluate a deep learning model for automated abnormality prediction with only TWIST sequences as input.

**Materials and Methods**

**Study population**

The initial population included 1447 breast MRI examinations from 809 patients who underwent breast MRI examinations between April 2016 and October 2019 at our institution. Of the 1447 examination the following MRI scans were excluded: 287 due to inconsistent protocol, 156 due to incomplete data and 159 due to another indication of scanning (34 response to chemotherapy, 94 surgery follow-up and 31 prosthesis rupture check). Furthermore, 8 examinations were excluded due to failed scan. The final data set consist of 837 examinations from 488 patients for deep learning model development and evaluation. Among the 837 examinations, 178 examinations from 149 patients were obtained after the deep learning model development, those data were used as an independent test set since they were not involved in the model development. The remaining 659 examinations from 339 patients were randomly assigned to 494 examinations from 214 patients for training and 165 examinations from 125 patients for validation. It should be noticed that the data was split on the patient level, thus there was no overlap in patients in the developing and independent test sets. Fig. 1 summarizes this process.

**MRI scanner and imaging technique**

Examinations were performed with a full diagnostic protocol (Fig. 2) on either a 3.0 T or 1.5 T scanner (MAGNETOM Skyra or MAGNETOM Avanto<sup>fit</sup>, Siemens, Erlangen, Germany) in the prone position. For 3.0 T and 1.5 T scanners, the full protocol takes 17.95 and 19.61 minutes, respectively, while the 15 TWIST acquisitions take 1.3 and 1.46 minutes. The acquisition parameters for ultrafast breast MRI are summarized in Table 3.

**Reference standard**

The labeling of the MRI examinations was based on the assessments and conclusions in the radiology reports, supplemented with pathology reports, biopsy, and ultrasound results. For each patient, the left and right breast were evaluated independently. Breasts with one or more visible enhanced lesion were labeled as abnormal, while breasts with unenhanced lesion or without suspicious lesion were then labeled as normal. Then, all the labels were further examined by a senior radiologist to ensure they are consistent with the visibility in TWIST. Examples of labeled breasts are shown in electronic supplementary material Fig. S1.

**Development of MIP-based Deep Learning System**

The proposed deep learning system had three main stages: breast region segmentation, MIP generation and abnormality prediction (Fig. 3).

For breast segmentation, a previously reported 3D U-Net \[18\] was adopted to generate the mask of the breast region. The segmentation was performed on T1-weighted fat-suppressed sequence acquired before contrast agent injection. The obtained masks were then mapped onto TWIST sequences by shape resize and FOV (field of view) alignment. Then the breast area was divided into left and right parts from the middle of the mask.

At the stage of MIP generation, only the last four TWIST acquisitions out of the fourteen post-contrast phases were used. Researches showed that, the time of arrival of benign lesions may be much longer than of malignant lesions\[19\]\[20\], thus most of the early MIPs contained no enhancing lesion. Therefore, to pinpoint as many lesions as possible and reduce computational burden, in this study, The generated MIP images were then used to train the deep learning model.

A ResNet-34 model \[21\], pre-trained on the ImageNet dataset, was modified and retrained for abnormality prediction. The output of the last fully connect layer of the model was changed to 2 to fit the task. ﻿The training data was then used for transfer learning and validation data was used for hyperparameter tuning. The tasks used for training were the presence or absence of visible lesions in the MIP image. During the training process, image augmentation was applied with random horizontal flip, random rotation within ﻿10° and random scaling within 10%. The batch size was set to 4, and the Adam optimizer was used. The final model was obtained by a 60 epochs training with an initial learning rate of 10<sup>−4</sup>. During inference, each of the 4 MIP images from a single breast were fed into the deep learning model, if any of them was predicted as positive, the breast was then determined as abnormal. The breast was only determined as lesion free when all the 4 MIP images were predicted as negative.

**Model Calibration and Evaluation**

To exploit the trained model to identify as many abnormal MRI exams as possible, a probability threshold which ensures a lower false negative rate (FNR) is preferable. On the other hand, for the purpose of reduce workload in the screening workflow, the false positive rate (FPR) should also be considered. To illustrate the relationship between FNR and FPR, the detection error tradeoff (DET) curve on the validation set was plotted. A threshold which enables a sensitivity of 100% or 95% and negative predictive value (NPV) above 98% on the validation set were then selected as high sensitivity thresholds.

To evaluate the prediction performance of the proposed deep learning system, receiver operating characteristic (ROC) curves on the independent test set was first generated for the calculation of area under the receiver operating curve (AUC). Sensitivity, specificity, positive predictive value (PPV), NPV were also calculated for the default and the high sensitivity thresholds, respectively. Furthermore, to help explain the decision-making of the classification model, Gradient-weighted Class Activation Mapping (Grad-CAM) was used to produce a coarse localization map, highlighting class-discriminative regions in each MIP image.

To evaluate the effect of the deep learning system on clinical workflow, we simulated the scenario that patients don’t need to accept further work -up if a negative prediction was derived from the TWIST sequences and that radiologists do not need to interpret those examinations. The reduced acquisition time and percentage of excluded MRI examinations were calculated based on this scenario.

﻿**Statistical Analysis**

﻿Medcalc (version 19.6.1 Medcalc Software Ltd, ﻿Ostend, Belgium) and ﻿scikit-learn (version 0.24.1; <https://scikit-learn.org>) were used for statistical analyses. The 95% confidence intervals (CI) for the AUCs were computed with DeLong’s method\[22\], 95% Clopper-Pearson CI for sensitivity and specificity, 95% standard logit CI\[23\] for PPV and NPV were also reported.

**Results**

**Patients and Lesions**

The training and validation sets consisted of 339 patients (median age ± standard deviation, 44 ± 11 years; range, 22–80 years) who underwent 659 screening breast MRI examinations. Among which, 494 examinations were used for model training and 165 for validation. Left and right breasts in each examination were labeled separately, which result in 118 abnormal breasts (lesion size ± standard deviation, 17.9 ± 17.4 mm; range, 5.0-110.0 mm) and 1200 normal breasts. 84 of the abnormal breasts contained benign lesions (lesion size ± standard deviation, 13.7 ± 12.8 mm; range, 5.0-81.0 mm) while the other 34 contained malignant lesions (lesion size ± standard deviation, 25.1 ± 19.8 mm; range, 6.0-110.0 mm).

The independent test set consisted of 149 patients (median age ± standard deviation, 44 ± 15 years; range, 24–76 years) who underwent 178 screening breast MRI examinations. On the breast level, 55 breasts were labeled as abnormal (lesion size ± standard deviation, 24.0 ± 19.8 mm; range, 5.0-76.0 mm) and 301 were labeled as normal. 25 of the 55 abnormal breasts contained benign lesions (lesion size ± standard deviation, 15.0 ± 16.1 mm; range, 5.0-75.0 mm) and 30 contained malignant lesions (lesion size ± standard deviation, 31.0 ± 19.4 mm; range, 6.0-76.0 mm). Detailed patient and lesion characteristics are provided in Table 1 and Table 2.

**Model Calibration**

The DET curve on the validation set which revealed the tradeoff between FPR and FNR with the threshold ranging from 0 to 1 is shown in Fig. 4. Two cutoff thresholds were selected based on the DET curve. With a threshold of 0.37, a sensitivity of 97% (30 of 31, 95% CI: 83%; 100%), and NPV of 98% (123 of 124, 95% CI: 95%; 99%) could be achieved. With this threshold, one breast with a benign lesion (chronic active inflammation with fat necrosis, 38mm) was misclassified in the validation set, no malignant lesion was missed. With a threshold of 0.25, a sensitivity of 100% (31 of 31, 95% CI: 89; 100) and NPV of 100% (74 of 74) could be achieved with no lesion missed.

**Independent Test**

On the independent test set, the model achieved an AUC of 0.81 (95% CI: 0.75; 0.88) (Fig. 5). With the threshold of 0.37, a sensitivity of 95% (52 of 55, 95% CI: 85%; 99%) and NPV of 97% (106 of 109, 95% CI: 92%; 99%) was achieved while with the threshold of 0.25, a sensitivity of 98% (54 of 55, 95% CI: 90%; 100%) and NPV of 98% (55 of 56, 95% CI: 89%; 100%) was achieved. The classification performance with each threshold is summarized in Table 4.

Heatmaps generated with Grad-CAM indicates that, for positive predictions, the model made the decision mainly based on the enhanced regions in the breast parenchyma, while for negative predictions, the model’s attention is always outside of the breast parenchyma. Examples are shown in Fig. 6.

**Standard Workflow vs Triage**

When applying a threshold of 0.37 on the independent test set, 3 breasts lesions were misclassified by the model, one contained a malignant lesion (mucinous carcinoma, 8mm, BI-RADS 6), while the other two contained benign lesions (one with Fibroadenoma, 9mm，BI-RADS 4 and one not biopsied, 6mm，BI-RADS 2). With the threshold of 0.25, no breast with malignant lesion but only the one with Fibroadenoma was misclassified.

Despite the possible risk of missing breast lesion, with a threshold of 0.37, 109 breasts were triaged as normal and 247 as abnormal, resulting a workload reduction of 30.6% (109 of 356) on breast level or 15.7% (28 of 178) on examination level. If continue lower the threshold to 0.25, 56 breasts were triaged as normal while 300 as abnormal, resulting a workload reduction of 15.7% (56 of 356) on breast level and 6.2% (11 of 178) on examination level. Meanwhile, 30.2% (982.2 of 3253.8 minutes) or 16.6% (538.8 of 3253.8 minutes) of scanner time could be saved from the 178 examinations under different setting, if only continue scanning when abnormal detected in ultrafast MRI.

**Discussion**

In this study, we combined clinical experience with artificial intelligence for the purpose of improving efficiency and accessibility of breast MRI screening. A deep learning model was developed to classify ultrafast breast MRI examinations as normal.

The model achieved an AUC of 0.81 (95% CI: 0.75; 0.88) on an independent test set. A high sensitivity (95% and 98%) and negative predicted values of (97% and 98%) was obtained by apply different thresholds (0.37 and 0.25). When integrated in the workflow, the model has potential to reduce radiologists’ workload by excluding normal scans and improving throughput by reducing scanning time. Moreover, the heatmap generated with Grad-CAM could also support radiologists’ image interpretation by indicating possible lesions in the MIP image.

Although a conservative strategy has been adopted, there were still false negative predictions. All missed lesions were smaller than 10 mm, the relatively small size may be the main reason that the deep learning model did not detect them. One malignant lesion (a mucinous carcinoma) was missed when using the threshold of 0.37. But it should be noted that there was only one mucinous carcinoma in the training dataset, the scarcity of this rare cancer might have caused the model to be insufficiently trained to identify it. 134 of the 195 false positive predicted breasts with threshold 0.37 were BI-RADS 2 and 113 were assessed within heterogeneously and extreme FGT. This indicate that, proper handling of dense and BI-RADS 2 breasts with moderate background enhancement may be the key to reducing false positive in the future.

Similar models have been developed or evaluated in other researches for screening\[24, 25\]. Verburg et al \[26\] developed a classification model with 4581 MRI examinations of extremely dense breasts, the model could help to excluded 39.7% of the MRI examinations without lesions﻿ and preserve 90.7% with lesions for radiologic review. Rodriguez-Ruiz et al\[27\] and Yala et al \[9\] showed that AI could help reduce 17% or 19.3% of workload for mammogram screening with a sensitivity of 90.6% or 90.1%, respectively. ﻿Raya-Povedano et al \[28\] also reported a 29.7% of workload reduction for tomosynthesis screening with a sensitivity of 84.1%. Even though the modality is different, the dilemma of using AI in triaging is the same: a lower threshold is safer but less efficient and the tradeoff between the risk of missing breast cancer and the reduction of workload is hard to determine.

One of the limitations in our study is that the model was developed with a high-risk population dataset collected from a single institution. This may affect the generalizability of this study. External validation with diverse populations is necessary before clinical implementation. Another limitation in this study is that the cancer rate in independent test set and training and validation set is not equal. Those two part of data was download separately from the same picture archiving and communication system during a time consuming acquisition process. This ensured independence but may introduce deviations in the reported results. In addition, we are limited in exploring the real effect of the deep learning model in the triage workflow. A double-blind, randomized clinical trial may be necessary to further evaluate the performance of the model. Meanwhile, the proposed method used the 3D mask derived from T1 weighted fat-suppressed sequences, which may introduce systematical error. Developing a TWIST based segmentation method might help further improve its performance.

In conclusion, the classification of ultrafast breast MRI examinations with deep learning model in the workflow may be promising to improve efficiency and accessibility of breast MRI screening. Reduced scanning and interpretation time results in significantly lower breast MRI screening costs, making it possible to provide MRI screening for a wider population.
